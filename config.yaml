BUFFER_SIZE: 1e5  # replay buffer size
BATCH_SIZE: 128  # minibatch size
GAMMA: 0.99  # discount factor
TAU: 1e-3  # for soft update of target parameters
LR_ACTOR: 2e-4  # learning rate of the actor
LR_CRITIC: 2e-4  # learning rate of the critic
WEIGHT_DECAY: 0  # L2 weight decay

ENVIRONMENT: /home/idriss/IDRISS/Udacity DRL/deep-reinforcement-learning/p2_continuous-control/Multi_Agent/Reacher.x86_64
device: cpu # Possible values cuda or cpu

n_episodes: 1400
max_t: 1000
TIME_STEPS: 20
UPDATE: 10
